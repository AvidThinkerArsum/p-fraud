{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-04-09 22:19:52.435235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns all the axes white in all the matplotlib plots. Comment this out if you dont want that\n",
    "COLOR = 'white'\n",
    "matplotlib.rcParams['text.color'] = COLOR\n",
    "matplotlib.rcParams['axes.labelcolor'] = COLOR\n",
    "matplotlib.rcParams['xtick.color'] = COLOR\n",
    "matplotlib.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = pd.read_csv('datasets/ieee-fraud-detection/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that are used, isFraud is the target\n",
    "features = ['isFraud', 'TransactionDT',\n",
    "            'TransactionAmt']\n",
    "\n",
    "df = df_transaction[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features into categorical and numerical types\n",
    "target = 'isFraud'\n",
    "# Categorical features\n",
    "cat = ['TransactionDT']\n",
    "# Numeric features\n",
    "num = ['TransactionAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Drop rows with missing features\n",
    "df = df.dropna()\n",
    "df = df[:10000]\n",
    "y = df[target].values\n",
    "df.head()\n",
    "df.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = df.filter(items = cat).values\n",
    "x_num = df.filter(items = num).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "# Label encode every categorical column\n",
    "for i in range(len(cat)): \n",
    "    x_cat[:, i] = labelencoder_X.fit_transform(x_cat[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build input vector X, the training data\n",
    "X = np.concatenate((x_cat, x_num), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7.1210e+03, 2.4500e+01],\n",
       "       [8.9390e+03, 1.5000e+02],\n",
       "       [2.9030e+03, 3.0000e+02],\n",
       "       [5.1120e+03, 5.0990e+01],\n",
       "       [3.4600e+02, 2.0995e+02],\n",
       "       [4.7000e+01, 3.5950e+00],\n",
       "       [7.6440e+03, 5.9000e+01],\n",
       "       [1.4890e+03, 1.0000e+02],\n",
       "       [7.2800e+03, 5.0000e+01],\n",
       "       [4.8300e+02, 1.0795e+02]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling - prepares training and test data for ML by standardizing features to have similar scales\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "#Y_train_std = sc.transform(y_train)\n",
    "#Y_test_std = sc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model_linear = SVC(C=.1,kernel='linear')\n",
    "model_linear.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.971\n"
     ]
    }
   ],
   "source": [
    "pred = model_linear.predict(X_test_std)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make a function to do all of this\n",
    "# inputs: lower bound, upper bound, step for C values, kernel type (linear, poly, rbf) \n",
    "\n",
    "def tuner(range, kernel):\n",
    "    ''' \n",
    "    range (list of floats): lower, upper, and step for values of c \n",
    "    kernel (str): 'linear', 'poly' 'rbf' (could also include sigmoid)\n",
    "    prints the accuracy of model of specified type with all c values in given range\n",
    "    '''\n",
    "    results = {}\n",
    "    for c in np.arange(range[0],range[1],range[2]):\n",
    "        model = SVC(C=c, kernel=kernel)\n",
    "        model.fit(X_train_std, y_train)\n",
    "        pred = model.predict(X_test_std)\n",
    "        results[c] = accuracy_score(y_test,pred)\n",
    "    for r in results:\n",
    "        print(kernel + \" model with regularization paramater \" + str(round(r,3)) + \" had accuracy \" + str(round(results[r],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner([.1,1,.2],'poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: recommended to scale your data before using an SVM, can be done using a pipeline, could try different kernel functions, look more into run-time of SVM"
   ]
  }
 ]
}