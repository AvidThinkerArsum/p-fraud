{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this as a base setup for training a neural network on the data\n",
    "\n",
    "# Dataset information - \n",
    "\n",
    " ### Transaction Dataset information\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distance\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n",
    "### Categorical Features:\n",
    "- ProductCD\n",
    "- card1 - card6\n",
    "- addr1, addr2(billing region, country)\n",
    "- P_emaildomain\n",
    "- R_emaildomain\n",
    "- M1 - M9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns all the axes white in all the matplotlib plots. Comment this out if you dont want that\n",
    "COLOR = 'white'\n",
    "matplotlib.rcParams['text.color'] = COLOR\n",
    "matplotlib.rcParams['axes.labelcolor'] = COLOR\n",
    "matplotlib.rcParams['xtick.color'] = COLOR\n",
    "matplotlib.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transaction = pd.read_csv('../datasets/ieee-fraud-detection/train_transaction.csv')\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that are used, isFraud is the target\n",
    "features = ['isFraud', 'TransactionDT',\n",
    "            'TransactionAmt','ProductCD', 'P_emaildomain','R_emaildomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>R_emaildomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>outlook.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionDT  TransactionAmt ProductCD P_emaildomain  \\\n",
       "0        0          86400            68.5         W           NaN   \n",
       "1        0          86401            29.0         W     gmail.com   \n",
       "2        0          86469            59.0         W   outlook.com   \n",
       "3        0          86499            50.0         W     yahoo.com   \n",
       "4        0          86506            50.0         H     gmail.com   \n",
       "\n",
       "  R_emaildomain  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_transaction[features]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 590540 rows and 6 columns.\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_cols = df.shape\n",
    "print(f\"The dataframe has {num_rows} rows and {num_cols} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPONSE VARIABLES:\n",
    "target = 'isFraud'\n",
    "# EXPLANATORY VARIABLES:\n",
    "# Categorical features\n",
    "cat = ['TransactionDT','ProductCD', 'P_emaildomain','R_emaildomain']\n",
    "# Numeric features\n",
    "num = ['TransactionAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe now has 126227 rows and 6 columns.\n"
     ]
    }
   ],
   "source": [
    "#Drop rows with missing features\n",
    "df = df.dropna()\n",
    "y = df[target].values\n",
    "num_rows, num_cols = df.shape\n",
    "print(f\"The dataframe now has {num_rows} rows and {num_cols} columns.\")\n",
    "# A lot of NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = df.filter(items = cat).values # n x 4 matrix\n",
    "x_num = df.filter(items = num).values # n x 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x_cat frame has 126227 rows and 4 columns. The x_num frame has 126227 rows and 1 columns.\n"
     ]
    }
   ],
   "source": [
    "rows_cat, cols_cat = x_cat.shape\n",
    "rows_num, cols_num = x_num.shape\n",
    "print(f\"The x_cat frame has {rows_cat} rows and {cols_cat} columns. The x_num frame has {rows_num} rows and {cols_num} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "# Label encode every categorical column\n",
    "# take column provide label and put back in column. Need only for categorical variable\n",
    "for i in range(len(cat)): \n",
    "    x_cat[:, i] = labelencoder_X.fit_transform(x_cat[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build input vector X, the training data\n",
    "X = np.concatenate((x_cat, x_num), axis=1) # n x 5 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) \n",
    "# X is categorical numerized and the numerical explanatory vavriables, y is the the numerical binary response\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "# split train into 80% train and 20% validation data - final performance in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype('float32') # np array of data type float\n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "X_val = np.asarray(X_val).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80784, 5), (80784, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "Model:\n",
    "Input -> Dense(Linear + activation) -> Dense -> Dense -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2521/2521 [==============================] - 3s 901us/step - loss: 81.0667 - accuracy: 0.8389\n",
      "Epoch 2/3\n",
      "2521/2521 [==============================] - 2s 837us/step - loss: 28.0413 - accuracy: 0.8443\n",
      "Epoch 3/3\n",
      "2521/2521 [==============================] - 2s 876us/step - loss: 12.0407 - accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81c89d7820>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = tf.keras.Sequential() # initializing the model\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # first dense layer with 128 neurons with rectified linear unit for a spectrum of values.\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # second layer\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)) # final layer with sigmoid for binary classification\n",
    "model.compile(optimizer='adam', # optomizing weight with adam using stochastic gradient descent\n",
    "              loss='binary_crossentropy', # evaluate perfromance of model with binary_crossentropy as output is binary\n",
    "              metrics=['accuracy']) # gives out accuracy of model\n",
    "model.fit(X_train, y_train, epochs=3) # pass training data 3 times through model and fit\n",
    "\n",
    "# loss is on training data, lower loss is good but might overfit\n",
    "# accuracy is on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631/631 [==============================] - 0s 571us/step - loss: 0.3715 - accuracy: 0.9203\n",
      "0.3715013861656189 0.9202539324760437\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(val_loss, val_acc)\n",
    "# accuracy is on validation data - performance in wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this as starter code to getting a neural network up\n",
    "\n",
    "Ideas going forward:\n",
    "- Add more features to the model\n",
    "- Use one-hot encoding instead of label-encoding\n",
    "- Figure out the meanings of hidden features\n",
    "- Categorize the email features into common vs uncommon emails\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2521/2521 [==============================] - 3s 979us/step - loss: 20.3424 - accuracy: 0.8587\n",
      "Epoch 2/3\n",
      "2521/2521 [==============================] - 2s 961us/step - loss: 0.5782 - accuracy: 0.9134\n",
      "Epoch 3/3\n",
      "2521/2521 [==============================] - 2s 948us/step - loss: 0.2881 - accuracy: 0.9163\n",
      "631/631 [==============================] - 0s 583us/step - loss: 0.2779 - accuracy: 0.9204\n",
      "0.2779393196105957 0.9204027056694031\n"
     ]
    }
   ],
   "source": [
    "# Adding extra dense layer decreases loss and increases accuracy\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) \n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)) \n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "model.fit(X_train, y_train, epochs=3)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2521/2521 [==============================] - 2s 839us/step - loss: 111.9182 - accuracy: 0.8381\n",
      "Epoch 2/3\n",
      "2521/2521 [==============================] - 2s 849us/step - loss: 34.2742 - accuracy: 0.8427\n",
      "Epoch 3/3\n",
      "2521/2521 [==============================] - 2s 987us/step - loss: 16.4278 - accuracy: 0.8441\n",
      "631/631 [==============================] - 0s 556us/step - loss: 4.1650 - accuracy: 0.9204\n",
      "4.164956569671631 0.9204027056694031\n"
     ]
    }
   ],
   "source": [
    "# Adding more features to the model\n",
    "features = ['isFraud', 'TransactionDT',\n",
    "            'TransactionAmt','ProductCD', 'P_emaildomain','R_emaildomain', 'card4']\n",
    "\n",
    "df = df_transaction[features]\n",
    "df.head()\n",
    "\n",
    "target = 'isFraud'\n",
    "cat = ['TransactionDT','ProductCD', 'P_emaildomain','R_emaildomain', 'card4']\n",
    "num = ['TransactionAmt']\n",
    "\n",
    "df = df.dropna()\n",
    "y = df[target].values\n",
    "\n",
    "x_cat = df.filter(items = cat).values \n",
    "x_num = df.filter(items = num).values\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(len(cat)): \n",
    "    x_cat[:, i] = labelencoder_X.fit_transform(x_cat[:, i])\n",
    "    \n",
    "X = np.concatenate((x_cat, x_num), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train = np.asarray(X_train).astype('float32') \n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "X_val = np.asarray(X_val).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32').reshape((-1,1))\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  \n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)) \n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "model.fit(X_train, y_train, epochs=3)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(val_loss, val_acc)\n",
    "\n",
    "# For same number of layers, adding the extra feature of card4 does not really enhance the predictive prowess of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
